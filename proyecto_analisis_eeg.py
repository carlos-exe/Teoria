# -*- coding: utf-8 -*-
"""PDS_ProyectoFinal

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BMYjtqCEG_T2BAOTXIjdfTMjgWgFL4WR

# Control de juego por emulador de nintendo utilizando registros de EEG

## 1. Representación utilizando espectro en frecuencia[lo que hemos visto hasta el 28/04], wavelets, y proyecciones basadas en varianza

--> adaptadación de esos modelos básicos de curos, para que sean manejables en tiempo real para hacer eficiente la toma
## 2. Codificar representación utilizando momentos estadísticos
---> toda esa info _trama_ que se recibe lo volvemos un segmento y luego un vector para decidir hacia donde se mueve el muñeco
## 3. Detección de intención de movimiento utilizando Bayes - bosques aleatorios

## 4. Manipular emulador desde control del teclado utilizando Python.

## 5. Visualizar canales y bandas de frecuencia relevantes para la detección  (interpretabilidad - Por qué?)

Probar en base de datos pública BCI competition 42a

###  1. Representación de señales
"""

# Cargar base de datos
#id del archivo: 1sui-FJI5znNJuQOk0whM6PALI89XfKss
FILEID = "1sui-FJI5znNJuQOk0whM6PALI89XfKss"  #descaragr base de dato desde drive
#1sui-FJI5znNJuQOk0whM6PALI89XfKss
!wget --load-cookies /tmp/cookies.txt "https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1\n/p')&id="$FILEID -O codigos.zip && rm -rf /tmp/cookies.txt
!unzip codigos.zip    # '!'llamando codigo de ocnsola o linux . -descomprime carpeta
!dir
!pip install mne==0.19   # toolbox que nos permite utilizar cosas del cerebro || asegurarme que trabajo con py 3.7 cuando mne 0.19

# Commented out IPython magic to ensure Python compatibility.
#importar paquetes
#importar carpeta con funciones
import sys
#agregar carpeta con funciones
sys.path.insert(1, './CodesBCIITL')  # al directorio del sistema (madre/root de py) agreguele tal carpeta, vaya y coja esa carpeta
# %matplotlib inline
from MIfunctions import * #importar todas las funciones de manejo de eeg con mne

import matplotlib.pyplot as plt
from scipy.signal import butter, filtfilt, lfilter, welch, lfilter_zi, stft #, freqz    filtros
import numpy as np
from mne.io import read_raw_edf
from mne.decoding import CSP
import pandas as pd
import json as  js #conda install -c jmcmurray json
import warnings
import seaborn as sns
import mne

from numpy import matlib
import os
from matplotlib.animation import FuncAnimation
from ipywidgets import interact

import cv2

from sklearn.pipeline import Pipeline
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.model_selection import ShuffleSplit, cross_val_score
from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score, cross_val_predict
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score
from joblib import dump, load
from sklearn.svm import LinearSVC, SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA


from mne.datasets import eegbci
from mne.io import concatenate_raws, read_raw_edf
from mne.channels import make_standard_montage
from mne import Epochs, pick_types, events_from_annotations

#crear carpeta con resultados_ guardar gráficas, modelos, etc en una carpeta, se vuelve.zip y se guarda
from google.colab import files
import os
try:
  os.mkdir('results')
except:
  print("Carpeta results ya existe")

import shutil
from datetime import date, datetime  #hacer copias de archivos y manejar tiempos

#cargar datos
#Descripcion base de datos
#https://drive.google.com/file/d/1354HvKfp8sMckvN2t3SR9OUo9Z0yE9Uv/view?usp=sharing

sbj = 9 #sujeto facil s03, sujeto dificil s02
name = './CodesBCIITL/data/A0' + str(sbj)
filename_train = name+'T.gdf'
Ch = np.arange(0,22)# lectura canales eeg || representando canales/a partir del numero de sensores del eje np.arange(start,stop[no lo toma])
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
clases = [769,770] # clases izquierda y derecha -> extender a pies y lengua, agregar  (771 y 772) || la codificación que se le dio a los eventos, solo carga trozos de eje cuando ocurre esa clase
# solo va acargar los trozos del eje donde hubo pistas de clase izq o derecha
vt = [-1.5,3.5] #escoger ventana de analisis de 2 segundos : -li:lf desde el estimulo cue # probar con ventana de 1 seg
# trozo de eje en donde imagina
#vt = [1.5,0.5] #escoger ventana de analisis : -li:lf desde el estimulo cue # probar con ventana de 1 seg
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
i_muestras, i_clases, raw, Xraw, y, ni,m = leer_bci42a_train_full(filename_train,clases,Ch,vt)
fs = raw.info['sfreq'] #frecuencia de muestreo
print(fs)

"""RAW DATA EN LOS 22 CANALES, TOMARON 500 PUNTOS
CON ESTO SE TOMA DECISIÓN DE LA INTENCIÓN
"""

print(Xraw.shape) # epoch (trials) x ch x #muestras a lo largo del registro (a f=250 por segundo, 500 puntos en el tiempo por canal) que presentan esa clase
print(y.shape)  # epoch del sujeto 9, de todo el registro que se tomo de trozos de imaginación motora donde pensó en las 10.clases por que es en la ventana de motor imagery
np.unique(y) #etiqueta si pensó en izquierda o derecha

Xraw[0].shape   # registro de los 22 canales en 2 segundos del primer intento '0'
y[0]  # es decir que es el 769, izquierda

"""Up: dibujo de los 22 canales en 2 segundos del inntento 1
Se si fue pensar izq o pensar derecho, en la y[1] pensó en 1:769.
"""

#eeg original trial i
i = 1
plot_eeg(data=Xraw[i],sample_rate=fs,channels_names=[raw.ch_names[i] for i in Ch])
plt.xlabel('t [s]')
plt.savefig('results/EEGOriginal.pdf', dpi=300)
y[i]

"""Segmentos concatenados cada uno de 2 segundos (épocas)"""

f = raw.plot() # 137 intentos, 22 canales, 625= 2.5*250: #muestras
f.savefig('results/EEGcompleto.pdf', dpi=300)
#Xraw[0]
print(raw)

"""# 1.a Representación por FFT  [extraction]

116 intentos
22  canales
251 --> la cantidad total de puntos, debido a los alias

nivel DC --> mueve, muecas, ruido

Utilizamos la rft, asume que la señal es real
"""

# fft por muestras eje = axis = 2 , 500 muestras por tiempo, es decir que mi eje de timepo es el de muestras| saque fourier a lo largo de las 500 muestras
Xrfft = abs(np.fft.rfft(Xraw,axis=2))
vf = np.fft.rfftfreq(Xraw.shape[2],1/fs)
Xrfft.shape
plt.plot(vf,Xrfft[y==1,11,:].T)
plt.xlabel('Hz')
plt.ylabel('$|X[w]| [dB]$')
plt.savefig('results/Ejfft.pdf', dpi=300)
plt.show()

plt.plot(vf,Xrfft[y==2,11,:].T)
plt.xlabel('Hz')
plt.ylabel('$|X[w]| [dB]$')
plt.show()
Xrfft.shape

"""La frecuencia maxima que puedo ver es 1/2 f de muestreo, es decir que puedo ver hasta 125 en frecuencia

NOTA: nos interesa la información en los ritmos cerebrales $\alpha\in[8,12] Hz$; $\beta\in[12,30] Hz$ para imaginación de movimiento

- Sobre la de WT 'Filtramos' no tomamos el nivel DC, filtro pasa-bandas

# 1.b Representación en STFT

STFT vemos un patrón en frecuencia a lo largo del tiempo y ayuda a tratar la no estacionariedad de la señal EEG.

NOtar que el patrón no estacionario, va saltando los niveles de enrgía, y por eso necesitamos ver la STFT para ver las secione sde interes y detectar el patrón.

esta cogiendo 100 muestras eb el tiempo y le calcula fourier, entonces cada intneto sobre cada canal 51, darían 11 ventanas. Si cambia el ancho del ventaneo cambia cantidad de ventanas y resolución.
"""

f,t,Xstft = stft(Xraw,fs=fs,nperseg=100,axis=2)
Xstft = abs(Xstft)
trail = 10
chi = 11

fig, ax = plt.subplots(2, 1)
vt = np.arange(0,Xraw.shape[2]/fs,1/fs)
ax[0].plot(vt,Xraw[trail,chi,:])
im = ax[1].pcolormesh(t, f, Xstft[trail,chi])
fig.colorbar(im, ax=ax[1],orientation="horizontal",pad=0.2)
plt.gca()
plt.xlabel('t [seg]')
plt.ylabel('f [Hz]')
plt.savefig('results/stft.pdf', dpi=300)

print(Xstft.shape) #epocas, Ch, puntos en frecuencia, #ventanas
print(f)
print(t)

"""# 1.c Wavelets - cwt

cmor:función base que se asemeja a la señal que quiero representar
se hace transpose (4), como son escalas y desplazamiento, entonces para que quede compatible en formato

- va quedando mucha info: 22 canales, 251 mestras, 116 intentos
"""

import pywt # EEG reales | cmor Wmadre | grafica señal EEG trabajada y espectro
#w = pywt.Wavelet('db4')
Xcwt,freq =pywt.cwt(Xraw,np.arange(1,50),'cmor',1/fs,axis=2)
Xcwt = abs(np.transpose(Xcwt,[1,2,0,3]))
Xcwt.shape

fig, ax = plt.subplots(2, 1)
vt = np.arange(0,Xraw.shape[2]/fs,1/fs)
ax[0].plot(vt,Xraw[trail,chi,:])
im = ax[1].pcolormesh(vt, freq, (Xcwt[trail,chi]))
fig.colorbar(im, ax=ax[1],orientation="horizontal",pad=0.2)
plt.gca()
plt.xlabel('t [seg]')
plt.ylabel('f [Hz]')

plt.savefig('results/cwt_cmor.pdf', dpi=300)

"""obs_and_28-07= Arriba: se observa como el espectro esta concentrado de 8 a 30, precisamente las bandas que me interesan, se ve le cambio de la dinámica y la no-estacionariedad (prendido a muy baja frecuencia)

# filtrado con cwt con Pycwt
"""

!pip install pycwt

import pycwt as wavelet
trial = 1
chi = 11
#MexicanHat
mother =  wavelet.MexicanHat() # wavelet.Morlet()
dj = 1/12 #resolucion en frecuencia
wave, scales, freqs, coi, fft, fftfreqs = wavelet.cwt(Xraw[trail,chi,:],dt=1/fs,wavelet=mother,dj=dj)#,freqs=np.fft.rfftfreq(Xraw.shape[2],1/fs))
ind = (freqs >= 8) & (freqs<=12)
wave[~ind,:] = 0
fig, ax = plt.subplots(2, 1)
vt = np.arange(0,Xraw.shape[2]/fs,1/fs)
ax[0].plot(vt,Xraw[trail,chi,:])
im = ax[1].pcolormesh(vt, freqs, abs(wave))
fig.colorbar(im, ax=ax[1],orientation="horizontal",pad=0.2)
plt.gca()
plt.xlabel('t [seg]')
plt.ylabel('f [Hz]')
plt.show()
print(wave.shape)

"""# filtrado con icwt"""

xe = wavelet.icwt(wave, scales, dt=1/fs,wavelet= mother,dj=dj)
#pintar espectro
vf = np.fft.rfftfreq(len(xe),1/fs)  # pasar eje x a Hz segun  numero de puntos y periodo muestreo
xefft = np.fft.rfft(xe)

plt.subplot(311)
plt.plot(vt,Xraw[trail,chi,:],label='original')
plt.legend()

plt.subplot(312)
plt.plot(vt,xe,label='filtered')
plt.legend()


plt.subplot(313)
plt.plot(vf,abs(xefft))
plt.xlabel('Hz')
plt.ylabel('$|X[w]|$')
plt.title('espectro filtrada')

plt.subplots_adjust(hspace=0.6,wspace=0.6)
plt.show()

"""- obs_and: Al final se calcula Fourier para comprobar que el espectro si quedó donde yo deseaba.

# 1.d PSD
"""

fpsd, Xpsd = welch(Xraw, fs=fs, nperseg=150,axis=2)
print(Xpsd.shape)
fpsd
plt.plot(fpsd,Xpsd[trail,chi,:])
plt.xlabel('f[Hz]')
plt.ylabel('PSD')
plt.show()
plt.savefig('results/psd.pdf', dpi=300)

fpsd

"""# 2.Codificar representación utilizando momentos estadísticos

# Codificar por momentos alpha y beta: stft, cwt
# fft y psd concatenar los valores del espectro en alpha y beta
"""

def cal_momentos(Xf): #se calcula momentos sobre ultimo eje
  #media, mediana, var, max, min
  m =np.c_[(Xf.mean(axis=-1),np.median(Xf,axis=-1),Xf.var(axis=-1),Xf.max(axis=-1),Xf.min(axis=-1))]
  return m

def representacion_(Xraw,banda1=[8,12],banda2=[12,30],fs=250,
                    nperseg_stft=100,scale_cwt=np.arange(1,50),nperseg_psd=150): #Xraw: trials, Ch, Tm
    trials,Ch,Tm = Xraw.shape
    #calculo fourier
    Xrfft = abs(np.fft.rfft(Xraw,axis=2)) # matriz 1 de atributos segun fft
    vf_fft = np.fft.rfftfreq(Xraw.shape[2],1/fs)
    #calculo stft
    vf_stft,_,Xstft = stft(Xraw,fs=fs,nperseg=nperseg_stft,axis=2)
    Xstft = abs(Xstft)
    #calculo cwt
    Xcwt,vf_cwt =pywt.cwt(Xraw,scale_cwt,'cmor',1/fs,axis=2)
    Xcwt = abs(np.transpose(Xcwt,[1,2,0,3]))
    #calculo psd
    vf_psd, Xpsd = welch(Xraw, fs=fs, nperseg=nperseg_psd,axis=2)

    ###concatenar por canales e intentos los momentos de stft y cwt en alpha y beta
    ### concatenar por canalues  e intentos los valores de fft y psd en  alpha y beta
    ind_fft_b1 = (vf_fft >= banda1[0]) & (vf_fft<=banda1[1])
    ind_fft_b2 = (vf_fft >= banda2[0]) & (vf_fft<=banda2[1])
    ind_stft_b1 = (vf_stft >= banda1[0]) & (vf_stft<=banda1[1])
    ind_stft_b2 = (vf_stft >= banda2[0]) & (vf_stft<=banda2[1])
    ind_cwt_b1 = (vf_cwt >= banda1[0]) & (vf_cwt<=banda1[1])
    ind_cwt_b2 = (vf_cwt >= banda2[0]) & (vf_cwt<=banda2[1])
    ind_psd_b1 = (vf_psd >= banda1[0]) & (vf_psd<=banda1[1])
    ind_psd_b2 = (vf_psd >= banda2[0]) & (vf_psd<=banda2[1])

    Fb1 = np.c_[(Xrfft[:,:,ind_fft_b1].reshape(trials,-1),
                 cal_momentos(Xstft[:,:,ind_stft_b1,:].reshape(trials,Ch,-1)).reshape(trials,-1),
                cal_momentos(Xcwt[:,:,ind_cwt_b1,:].reshape(trials,Ch,-1)).reshape(trials,-1),
                 Xpsd[:,:,ind_psd_b1].reshape(trials,-1))]

    Fb2 = np.c_[(cal_momentos(Xrfft[:,:,ind_fft_b2]).reshape(trials,-1),
                cal_momentos(Xstft[:,:,ind_stft_b2,:].reshape(trials,Ch,-1)).reshape(trials,-1),
                cal_momentos(Xcwt[:,:,ind_cwt_b2,:].reshape(trials,Ch,-1)).reshape(trials,-1),
                 Xpsd[:,:,ind_psd_b2].reshape(trials,-1))]

    tam = [np.array([sum(ind_fft_b1),5,5,sum(ind_psd_b1)]),np.array([5,5,5,sum(ind_psd_b2)])]

    return Fb1,Fb2,tam # Rep [trials,P]; P = #Ch, #bandas=2, #mommentos por cwt y stft, #valores psd y fft

Fb1,Fb2,tam = representacion_(Xraw)
Xdata_rep = np.c_[(Fb1,Fb2)]

print(tam)
print(Fb1.shape)
print(Fb2.shape)
print(Xdata_rep.shape)

"""## Filtrado digital y espectral generalizado

$H(w)=Re\{H(w)\}+jIm\{H(w)\}=|H(w)|e^{j\theta_H}=r(\cos(\theta_H)+j\sin(\theta_H))$

$x_f(t)=x(t)*h(t);$ $X_f(w)=X(w)H(w)=|X(w)||H(w)|e^{j\theta_X}e^{j\theta_H}$
$$X_f(w)=X(w)H(w)=|X(w)||H(w)|e^{j(\theta_X+\theta_H)}$$

$$X(w)e^{j\theta_H}=X(w)e^{j\omega_Ht_H}$$

$$\mathcal{F}\{x(t \pm t_o)\}=X(w)e^{\mp jw t_o}$$
"""

# Filtro pasabanda según ritmos cerebrales
#filtro butterworth
#filtfilt y lfilter
from scipy import signal
trial = 0
ch = 11
data = Xraw[trial,ch,:] #trial, ch, muestras

plt.figure(figsize=(8,4))
plt.subplot(231)
plt.plot(data,label='original')
plt.legend()

#diseñar filtro
lowcut = 8
highcut = 12
order = 5
b, a = butter_bandpass(lowcut, highcut, fs, order=order)#diseño
w, h = signal.freqz(b,a,fs=fs)
#graficar magnitud
plt.subplot(232)
plt.plot(w, 20 * np.log10(abs(h)), 'b')
#plt.plot(w, abs(h), 'b')
plt.xlabel('Hz')
plt.ylabel('|H[w]|dB')


#graficar fase
angles = np.unwrap(np.angle(h))
plt.subplot(233)
plt.plot(w, angles, 'g')
plt.xlabel('Hz')
plt.ylabel('<H[w]')

plt.subplot(234)
yy = signal.lfilter(b, a, data)
plt.plot(y,label='lfilter')
yy = signal.filtfilt(b,a,data)
plt.plot(yy,label='filtfilt')
plt.legend()

plt.subplot(235)
Yw = np.fft.rfft(yy)
fv = np.fft.rfftfreq(yy.shape[0],1/fs)
plt.plot(fv,abs(Yw))

plt.subplot(236)
Yo = np.fft.rfft(data)
fv = np.fft.rfftfreq(data.shape[0],1/fs)
plt.plot(fv,abs(Yo))
plt.subplots_adjust(hspace=0.6,wspace=0.6)
plt.show()

ind = (fv >= lowcut ) & (fv <= highcut)
Yo2 = Yo
Yo[~ind] = 0
xef = np.fft.irfft(Yo)

plt.plot(fv, abs(Yo))
plt.show()
plt.plot(xef)



#https://en.wikipedia.org/wiki/Neural_oscillation
#ver funcionamiento caracterizacion de common spatial patterns -> especial para motor imagery
#https://en.wikipedia.org/wiki/Common_spatial_pattern
#https://es.slideshare.net/yokotatsuya/introduction-to-common-spatial-pattern-filters-for-eeg-motor-imagery-classification
f_frec = np.array([[8,12],[12,30]])
csp = CSP_epochs_filter_extractor(fs=fs,f_frec=f_frec,ncomp = Xraw.shape[1],reg='empirical')
Xdata_csp = csp.fit_transform(Xraw,y)
print(Xraw.shape,Xdata_csp.shape)

#se deben ajustar los nombres de los canales al montaje 10-20 de mne
montage = mne.channels.read_montage('standard_1020') #"standard_1020"
#montage = mne.channels.make_standard_montage(kind='biosemi64')
info = mne.create_info(montage.ch_names, sfreq=250, ch_types="eeg",
                           montage=montage)
f,ax = plt.subplots(1,1,figsize=(3,3))
mne.viz.plot_sensors(info, show_names=True,axes=ax)
plt.show()
#canales base de datos
channels_names = ['Fz','FC3','FC1','FCz','FC2','FC4',
                 'C5','C3','C1','Cz','C2','C4','C6',
                 'CP3','CP1','CPz','CP2','CP4',
                  'P1','Pz','P2',
                   'POz']
# Se crea un objeto mne con el montaje de los electrodos usados
montage = mne.channels.read_montage('standard_1020', channels_names)
info = mne.create_info(channels_names, sfreq=250, ch_types="eeg",
                           montage=montage)
f,ax = plt.subplots(1,1,figsize=(3,3))
mne.viz.plot_sensors(info, show_names=True,axes=ax)
f.savefig('results/MontageBCI42a.pdf', dpi=300)

#visualizar en topoplot (grafica sobre sensores), canales con mas peso por representacion por bandas desde csp
f, ax = plt.subplots(1,len(csp.csp_l),figsize=(12,3))
rhov = np.zeros((csp.csp_l[0].filters_.shape[1],len(csp.csp_l)))
cmap = 'jet'
for i in range(len(csp.csp_l)):
    #rhov[:,i] = np.mean(abs(csp.csp_l[i].filters_),axis=0) #promediar pesos sobre representacion de csp
    rhov[:,i] = abs(csp.csp_l[i].filters_[0]) #promediar pesos sobre representacion de csp
    rhov[:,i] = rhov[:,i]/max(rhov[:,i])
    mne.viz.plot_topomap(rhov[:,i], info, axes=ax[i], show=False,cmap=cmap)
    ax[i].set_title('Band '+str(f_frec[i])+'[Hz]')

cax = f.add_axes([0.95, 0.15, 0.02, 0.75])
norm = matplotlib.colors.Normalize(vmin=0,vmax=1)
sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
sm.set_array([])
plt.colorbar(sm,cax=cax)
plt.savefig('results/Relevancia_CSPFilters_0.pdf', dpi=300)
plt.show()

csp.csp_l[0].filters_.shape

Xdata = np.c_[(Xdata_rep,Xdata_csp)]
print(Xdata_rep.shape)
print(Xdata_csp.shape)
print(Xdata.shape)

plt.imshow(Xdata)
plt.colorbar()

from sklearn.ensemble import RandomForestClassifier


from sklearn.model_selection import cross_val_predict

steps = [('scaler',StandardScaler()),
         ('cla', RandomForestClassifier())]

model = Pipeline(steps)
ye = cross_val_predict(model,Xdata,y,cv=10,verbose = 50)

cm = confusion_matrix(y, ye)
cm = 100*cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
acc = accuracy_score(y,ye)
plot_confusion_matrix_MS(cm, np.zeros(cm.shape), np.unique(y))
plt.title('${Acc}$='+ format(100*acc,'.1f') )
plt.show()

model.fit(Xdata,y)
rho = model['cla'].feature_importances_
rho /=rho.max()
plt.stem(rho)
plt.show()
print(Xdata.shape)

#construir funcion que permita mapear al espacio de canales la importancia de cada tipo de representacion en rho
# por banda
#ej: dibuje topoplot de fourier en banda  mu

# guardar con joblib
from joblib import dump, load
savedata = {
        'cm':cm,
        'rho': rho,
        'model':model,
          }
dump(savedata,'modeleeg.joblib')

model_load = load('modeleeg.joblib')

'''
from pynput.keyboard import Controller #Key
import time
left = 'a'
right = 'd'
tmax = 1
keyboard = Controller()
ii = 0

while ii < nepochs: #while true or input = xxxx
    print('epoch %d/%d\n'% (ii+1,nepochs))

    y_pro = model.predict(Xdata[ii,:,:].reshape(1,-1)) # Xraw debe incluir representacion

    if (y_pro == 1):
        keyboard.press(left)
        print('%s__epoch:%d' % (left,ii+1))
        time.sleep(tmax)
        keyboard.release(left)

    elif (y_pro == 2):
        keyboard.press(right)
        print('%s__epoch:%d' % (right,ii+1))
        time.sleep(tmax)
        keyboard.release(right)

    ii+=1
#%%
'''

#model_load['model'].predict(Xnew)

